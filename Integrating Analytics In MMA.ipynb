{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating Analytics in MMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /opt/anaconda3/lib/python3.9/site-packages (from kaggle) (1.16.0)\n",
      "Collecting certifi>=2023.7.22\n",
      "  Downloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.0/163.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /opt/anaconda3/lib/python3.9/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.9/site-packages (from kaggle) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.9/site-packages (from kaggle) (4.64.1)\n",
      "Requirement already satisfied: python-slugify in /opt/anaconda3/lib/python3.9/site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in /opt/anaconda3/lib/python3.9/site-packages (from kaggle) (1.26.11)\n",
      "Requirement already satisfied: bleach in /opt/anaconda3/lib/python3.9/site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.9/site-packages (from bleach->kaggle) (21.3)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.9/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/anaconda3/lib/python3.9/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/anaconda3/lib/python3.9/site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests->kaggle) (3.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/lib/python3.9/site-packages (from packaging->bleach->kaggle) (3.0.9)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105789 sha256=1e42be61b762c737d560ea7d34f337628701a8ca72d12f9b1c60419abc8b2b90\n",
      "  Stored in directory: /Users/zacurbiztondo/Library/Caches/pip/wheels/2b/af/a9/70bffa2773af622d2ebea9c8d407720b86e67bd40c465bf837\n",
      "Successfully built kaggle\n",
      "Installing collected packages: certifi, kaggle\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2022.12.7\n",
      "    Uninstalling certifi-2022.12.7:\n",
      "      Successfully uninstalled certifi-2022.12.7\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.20 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.20 requires nbformat==5.4.0, but you have nbformat 5.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed certifi-2024.7.4 kaggle-1.6.17\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in initial datasets\n",
    "ufc_data = pd.read_csv('./UFC_Final_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fighter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Reach</th>\n",
       "      <th>DOB</th>\n",
       "      <th>SLpM</th>\n",
       "      <th>Str_Acc</th>\n",
       "      <th>SApM</th>\n",
       "      <th>Str_Def</th>\n",
       "      <th>TD_Avg</th>\n",
       "      <th>...</th>\n",
       "      <th>min_win_streak</th>\n",
       "      <th>avg_odds</th>\n",
       "      <th>avg_lose_streak</th>\n",
       "      <th>avg_win_streak</th>\n",
       "      <th>Decision%</th>\n",
       "      <th>KO/TKO%</th>\n",
       "      <th>Submission%</th>\n",
       "      <th>Weightclass</th>\n",
       "      <th>Champion</th>\n",
       "      <th>Style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Papy Abedi</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>185 lbs.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30-Jun-78</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.48</td>\n",
       "      <td>3.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Middleweight</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shamil Abdurakhimov</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>235 lbs.</td>\n",
       "      <td>76\"</td>\n",
       "      <td>2-Sep-81</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Heavyweight</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ricardo Abreu</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>185 lbs.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27-Apr-84</td>\n",
       "      <td>3.79</td>\n",
       "      <td>0.31</td>\n",
       "      <td>3.98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-247.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Middleweight</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daichi Abe</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>170 lbs.</td>\n",
       "      <td>71\"</td>\n",
       "      <td>27-Nov-91</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.33</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Welterweight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Klidson Abreu</td>\n",
       "      <td>6' 0\"</td>\n",
       "      <td>205 lbs.</td>\n",
       "      <td>74\"</td>\n",
       "      <td>24-Dec-92</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Light-Heavyweight</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>Zhang Weili</td>\n",
       "      <td>5' 4\"</td>\n",
       "      <td>115 lbs.</td>\n",
       "      <td>63\"</td>\n",
       "      <td>13-Aug-89</td>\n",
       "      <td>6.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>4.43</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.26</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Strawweight</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>Zhalgas Zhumagulov</td>\n",
       "      <td>5' 4\"</td>\n",
       "      <td>125 lbs.</td>\n",
       "      <td>66\"</td>\n",
       "      <td>29-Aug-88</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.49</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-118.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>flyweight</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>Fares Ziam</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>155 lbs.</td>\n",
       "      <td>75\"</td>\n",
       "      <td>21-Mar-97</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>137.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lightweight</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>Cat Zingano</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>145 lbs.</td>\n",
       "      <td>68\"</td>\n",
       "      <td>1-Jul-82</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2.77</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>212.5</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>featherweight</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>Joao Zeferino</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>170 lbs.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15-Jan-86</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Welterweight</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1447 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fighter  Height    Weight Reach        DOB  SLpM  Str_Acc  \\\n",
       "0              Papy Abedi  5' 11\"  185 lbs.   NaN  30-Jun-78  2.80     0.55   \n",
       "1     Shamil Abdurakhimov   6' 3\"  235 lbs.   76\"   2-Sep-81  2.45     0.44   \n",
       "2           Ricardo Abreu  5' 11\"  185 lbs.   NaN  27-Apr-84  3.79     0.31   \n",
       "3              Daichi Abe  5' 11\"  170 lbs.   71\"  27-Nov-91  3.80     0.33   \n",
       "4           Klidson Abreu   6' 0\"  205 lbs.   74\"  24-Dec-92  2.05     0.40   \n",
       "...                   ...     ...       ...   ...        ...   ...      ...   \n",
       "1442          Zhang Weili   5' 4\"  115 lbs.   63\"  13-Aug-89  6.38     0.45   \n",
       "1443   Zhalgas Zhumagulov   5' 4\"  125 lbs.   66\"  29-Aug-88  4.17     0.49   \n",
       "1444           Fares Ziam   6' 1\"  155 lbs.   75\"  21-Mar-97  1.90     0.47   \n",
       "1445          Cat Zingano   5' 6\"  145 lbs.   68\"   1-Jul-82  2.57     0.61   \n",
       "1446        Joao Zeferino  5' 11\"  170 lbs.   NaN  15-Jan-86  0.83     0.36   \n",
       "\n",
       "      SApM  Str_Def  TD_Avg  ...  min_win_streak  avg_odds  avg_lose_streak  \\\n",
       "0     3.15     0.48    3.47  ...               0     295.0         1.500000   \n",
       "1     2.45     0.58    1.23  ...               0      60.0         0.333333   \n",
       "2     3.98     0.68    2.13  ...               0    -247.5         0.000000   \n",
       "3     4.49     0.56    0.33  ...               0     100.0         0.500000   \n",
       "4     2.90     0.55    0.64  ...               0       8.0         0.500000   \n",
       "...    ...      ...     ...  ...             ...       ...              ...   \n",
       "1442  4.43     0.53    1.26  ...               5     170.0         0.000000   \n",
       "1443  4.00     0.58    1.50  ...               0    -118.0         2.000000   \n",
       "1444  1.37     0.66    0.50  ...               1     137.5         0.500000   \n",
       "1445  1.63     0.47    2.77  ...               0     212.5         1.200000   \n",
       "1446  2.60     0.48    0.50  ...               0     270.0         1.000000   \n",
       "\n",
       "      avg_win_streak  Decision%   KO/TKO%  Submission%        Weightclass  \\\n",
       "0           0.500000   1.000000  0.000000          0.0       Middleweight   \n",
       "1           1.333333   0.600000  0.400000          0.0        Heavyweight   \n",
       "2           0.500000   0.000000  0.000000          1.0       Middleweight   \n",
       "3           0.500000   1.000000  0.000000          0.0       Welterweight   \n",
       "4           0.250000   1.000000  0.000000          0.0  Light-Heavyweight   \n",
       "...              ...        ...       ...          ...                ...   \n",
       "1442        5.000000   0.600000  0.200000          0.2        Strawweight   \n",
       "1443        0.000000   0.000000  0.000000          0.0          flyweight   \n",
       "1444        1.000000   1.000000  0.000000          0.0        Lightweight   \n",
       "1445        1.000000   0.333333  0.666667          0.0      featherweight   \n",
       "1446        0.000000   0.000000  0.000000          0.0       Welterweight   \n",
       "\n",
       "     Champion  Style  \n",
       "0           0      6  \n",
       "1           0      6  \n",
       "2           0      4  \n",
       "3           0      0  \n",
       "4           0      5  \n",
       "...       ...    ...  \n",
       "1442        1      1  \n",
       "1443        0      5  \n",
       "1444        0      7  \n",
       "1445        0      1  \n",
       "1446        0      1  \n",
       "\n",
       "[1447 rows x 68 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufc_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get champions (target variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_data_titles = ufc_data[ufc_data['title_bout'] == True][['Winner', 'title_bout', 'R_fighter', 'B_fighter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_data_titles['Winner'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_data_titles.loc[(ufc_data_titles['Winner'] == 'Red'), 'Winner_Name'] = ufc_data_titles['R_fighter']\n",
    "ufc_data_titles.loc[(ufc_data_titles['Winner'] == 'Blue'), 'Winner_Name'] = ufc_data_titles['B_fighter']\n",
    "ufc_data_titles.loc[(ufc_data_titles['Winner'] == 'Draw'), 'Winner_Name'] = ufc_data_titles['R_fighter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Draws: decided to give them both the win...you can change this if you need. wiki tends to say they're both champs? i dont know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draws = ufc_data[(ufc_data['title_bout'] == True) & (ufc_data['Winner'] == 'Draw')]\n",
    "#draw_champs = list(draws['B_fighter'].append(draws['R_fighter']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate Red Corner and Blue Corner Fighters\n",
    "ufc_master_R = ufc_master.filter(regex='^R', axis='columns')\n",
    "ufc_master_B = ufc_master.filter(regex='^B', axis='columns')\n",
    "\n",
    "#General Preprocessing\n",
    "ufc_master_R['R_fighter'] = ufc_master_R['R_fighter'].str.lstrip()\n",
    "ufc_master_B['B_fighter'] = ufc_master_B['B_fighter'].str.lstrip()\n",
    "\n",
    "#Preprocessing for Red Corner Data\n",
    "#Column as is\n",
    "ufc_master_R_std = ufc_master_R[['R_fighter','R_Stance','R_Height_cms','R_Reach_cms','R_Weight_lbs']].groupby(['R_fighter']).first()\n",
    "#Max values for columns\n",
    "ufc_master_R_max = ufc_master_R[['R_fighter','R_current_lose_streak','R_current_win_streak','R_losses','R_total_rounds_fought',\n",
    "                                 'R_win_by_Decision_Majority','R_win_by_Decision_Split','R_win_by_Decision_Unanimous',\n",
    "                                 'R_win_by_KO/TKO','R_win_by_Submission','R_win_by_TKO_Doctor_Stoppage','R_wins']] \\\n",
    "                                .groupby(['R_fighter']).max()\n",
    "ufc_master_R_max = ufc_master_R_max.rename(columns={'R_current_lose_streak':'R_max_lose_streak',\n",
    "                                                    'R_current_win_streak':'R_max_win_streak'})\n",
    "#Min values for columns\n",
    "ufc_master_R_min = ufc_master_R[['R_fighter','R_current_lose_streak','R_current_win_streak']] \\\n",
    "                                .groupby(['R_fighter']).min()\n",
    "ufc_master_R_min = ufc_master_R_min.rename(columns={'R_current_lose_streak':'R_min_lose_streak',\n",
    "                                                    'R_current_win_streak':'R_min_win_streak'})\n",
    "#Avg values for columns\n",
    "ufc_master_R_avg = ufc_master_R[['R_fighter','R_odds','R_current_lose_streak','R_current_win_streak']].groupby(['R_fighter']).mean()\n",
    "ufc_master_R_avg = ufc_master_R_avg.rename(columns={'R_odds':'R_avg_odds',\n",
    "                                                    'R_current_lose_streak':'R_avg_lose_streak',\n",
    "                                                    'R_current_win_streak':'R_avg_win_streak'})\n",
    "#Combine R dataframes\n",
    "ufc_master_R_final = pd.concat([ufc_master_R_std,  ufc_master_R_max,\n",
    "                                ufc_master_R_min, ufc_master_R_avg], axis=1).reset_index()                                                                                                 \n",
    "                    \n",
    "#Preprocessing for Blue Corner Data\n",
    "#Column as is\n",
    "ufc_master_B_std = ufc_master_B[['B_fighter','B_Stance','B_Height_cms','B_Reach_cms','B_Weight_lbs']].groupby(['B_fighter']).first()\n",
    "#Max values for columns\n",
    "ufc_master_B_max = ufc_master_B[['B_fighter','B_current_lose_streak','B_current_win_streak','B_losses','B_total_rounds_fought',\n",
    "                                 'B_win_by_Decision_Majority','B_win_by_Decision_Split','B_win_by_Decision_Unanimous',\n",
    "                                 'B_win_by_KO/TKO','B_win_by_Submission','B_win_by_TKO_Doctor_Stoppage', 'B_wins']] \\\n",
    "                                .groupby(['B_fighter']).max()\n",
    "ufc_master_B_max = ufc_master_B_max.rename(columns={'B_current_lose_streak':'B_max_lose_streak',\n",
    "                                                    'B_current_win_streak':'B_max_win_streak'})\n",
    "#Min values for columns\n",
    "ufc_master_B_min = ufc_master_B[['B_fighter','B_current_lose_streak','B_current_win_streak']] \\\n",
    "                                .groupby(['B_fighter']).min()\n",
    "ufc_master_B_min = ufc_master_B_min.rename(columns={'B_current_lose_streak':'B_min_lose_streak',\n",
    "                                                    'B_current_win_streak':'B_min_win_streak'})\n",
    "#Avg values for columns\n",
    "ufc_master_B_avg = ufc_master_B[['B_fighter','B_odds','B_current_lose_streak','B_current_win_streak']].groupby(['B_fighter']).mean()\n",
    "ufc_master_B_avg = ufc_master_B_avg.rename(columns={'B_odds':'B_avg_odds',\n",
    "                                                    'B_current_lose_streak':'B_avg_lose_streak',\n",
    "                                                    'B_current_win_streak':'B_avg_win_streak'})\n",
    "#Combine B dataframes\n",
    "ufc_master_B_final = pd.concat([ufc_master_B_std,  ufc_master_B_max,\n",
    "                                ufc_master_B_min, ufc_master_B_avg], axis=1).reset_index()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge ufc_master_std dataframes to build portion of fighter profile\n",
    "ufc_master_final = pd.concat([ufc_master_R_std,  ufc_master_B_std], axis=1).reset_index()\n",
    "ufc_master_final = ufc_master_final.rename(columns={'index':'fighter'})\n",
    "\n",
    "#Consolidate initial_ufc_master features\n",
    "initial_columns = {}\n",
    "initial_features = ['Stance','Height_cms','Reach_cms','Weight_lbs']\n",
    "#Populate Dictionary keys with lists for fighter initial features and append to dataframe\n",
    "for feature in initial_features:\n",
    "    ph = []\n",
    "    for row in ufc_master_final.itertuples():\n",
    "        if pd.isna(row.R_Stance) & pd.isna(row.R_Height_cms):\n",
    "            ph.append(ufc_master_B_final.loc[ufc_master_B_final['B_fighter'] == row.fighter]['B_'+feature].values[0])\n",
    "        elif pd.isna(row.B_Stance) & pd.isna(row.B_Height_cms):\n",
    "            ph.append(ufc_master_R_final.loc[ufc_master_R_final['R_fighter'] == row.fighter]['R_'+feature].values[0])\n",
    "        else:\n",
    "            ph.append(ufc_master_B_final.loc[ufc_master_B_final['B_fighter'] == row.fighter]['B_'+feature].values[0])\n",
    "    initial_columns[feature] = ph\n",
    "    ufc_master_final[feature] = initial_columns[feature]\n",
    "\n",
    "#Create Dictionary as placeholder for new ufc_master_final columns\n",
    "additional_columns = {}\n",
    "additional_features = ['max_lose_streak', 'max_win_streak', 'losses','total_rounds_fought', 'win_by_Decision_Majority',\n",
    "                       'win_by_Decision_Split', 'win_by_Decision_Unanimous', 'win_by_KO/TKO', 'win_by_Submission',\n",
    "                       'win_by_TKO_Doctor_Stoppage', 'wins', 'min_lose_streak', 'min_win_streak','avg_odds', \n",
    "                       'avg_lose_streak', 'avg_win_streak']\n",
    "#Populate Dictionary keys with lists for fighter stats and append to dataframe\n",
    "for feature in additional_features:\n",
    "    ph = []\n",
    "    for row in ufc_master_final.itertuples():\n",
    "        if pd.isna(row.R_Stance) & pd.isna(row.R_Height_cms):\n",
    "            ph.append(ufc_master_B_final.loc[ufc_master_B_final['B_fighter'] == row.fighter]['B_'+feature].values[0])\n",
    "        elif pd.isna(row.B_Stance) & pd.isna(row.B_Height_cms):\n",
    "            ph.append(ufc_master_R_final.loc[ufc_master_R_final['R_fighter'] == row.fighter]['R_'+feature].values[0])\n",
    "        else:\n",
    "            ph.append(max((ufc_master_R_final.loc[ufc_master_R_final['R_fighter'] ==  row.fighter]['R_'+feature].values[0]),\n",
    "                          (ufc_master_B_final.loc[ufc_master_B_final['B_fighter'] ==  row.fighter]['B_'+feature].values[0])))\n",
    "    additional_columns[feature] = ph\n",
    "    ufc_master_final[feature] = additional_columns[feature]\n",
    "    \n",
    "#Drop previous R/B columns\n",
    "ufc_master_final.drop(ufc_master_final.columns.difference(initial_features+additional_features+['fighter']), 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Win Condition Columns to Percentages\n",
    "ufc_master_final['Decision%'] = (ufc_master_final['win_by_Decision_Majority'] + \\\n",
    "                                ufc_master_final['win_by_Decision_Split'] + \\\n",
    "                                ufc_master_final['win_by_Decision_Unanimous']) / ufc_master_final['wins']                                            \n",
    "ufc_master_final['KO/TKO%'] = (ufc_master_final['win_by_KO/TKO'] + \\\n",
    "                               ufc_master_final['win_by_TKO_Doctor_Stoppage']) / ufc_master_final['wins']\n",
    "ufc_master_final['Submission%'] = ufc_master_final['win_by_Submission'] / ufc_master_final['wins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DROP NAN VALUES SPARINGLY##\n",
    "ufc_master_final.isna().sum()\n",
    "ufc_master_final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate Red Corner and Blue Corner Fighters with Select Features\n",
    "#Red Corner\n",
    "ufc_data_R = ufc_data[['R_fighter','date','R_avg_KD','R_avg_SIG_STR_pct','R_avg_SUB_ATT','R_avg_REV',\n",
    "                         'R_avg_SIG_STR_att','R_avg_SIG_STR_landed','R_avg_TD_att','R_avg_TD_landed','R_avg_HEAD_att',\n",
    "                         'R_avg_HEAD_landed','R_avg_BODY_att','R_avg_BODY_landed','R_avg_LEG_att','R_avg_LEG_landed',\n",
    "                         'R_avg_DISTANCE_att','R_avg_DISTANCE_landed','R_avg_CLINCH_att','R_avg_CLINCH_landed',\n",
    "                         'R_avg_GROUND_att','R_avg_GROUND_landed','R_avg_CTRL_time(seconds)','R_total_title_bouts','R_age']] \\\n",
    "                         .groupby(['R_fighter']).first().reset_index()\n",
    "\n",
    "ufc_data_R['R_fighter'] = ufc_data_R['R_fighter'].str.strip()\n",
    "ufc_data_R = ufc_data_R.rename(columns={'R_fighter':'fighter',\n",
    "                                        'R_avg_KD':'avg_KD',\n",
    "                                        'R_avg_SIG_STR_pct':'avg_SIG_STR_pct',\n",
    "                                        'R_avg_SUB_ATT':'avg_SUB_ATT',\n",
    "                                        'R_avg_REV':'avg_REV',\n",
    "                                        'R_avg_SIG_STR_att':'avg_SIG_STR_att',\n",
    "                                        'R_avg_SIG_STR_landed':'avg_SIG_STR_landed',\n",
    "                                        'R_avg_TD_att':'avg_TD_att',\n",
    "                                        'R_avg_TD_landed':'avg_TD_landed',\n",
    "                                        'R_avg_HEAD_att':'avg_HEAD_att',\n",
    "                                        'R_avg_HEAD_landed':'avg_HEAD_landed',\n",
    "                                        'R_avg_BODY_att':'avg_BODY_att',\n",
    "                                        'R_avg_BODY_landed':'avg_BODY_landed',\n",
    "                                        'R_avg_LEG_att':'avg_LEG_att',\n",
    "                                        'R_avg_LEG_landed':'avg_LEG_landed',\n",
    "                                        'R_avg_DISTANCE_att':'avg_DISTANCE_att',\n",
    "                                        'R_avg_DISTANCE_landed':'avg_DISTANCE_landed',\n",
    "                                        'R_avg_CLINCH_att':'avg_CLINCH_att',\n",
    "                                        'R_avg_CLINCH_landed':'avg_CLINCH_landed',\n",
    "                                        'R_avg_GROUND_att':'avg_GROUND_att',\n",
    "                                        'R_avg_GROUND_landed':'avg_GROUND_landed',\n",
    "                                        'R_avg_CTRL_time(seconds)':'avg_CTRL_time(seconds)',\n",
    "                                        'R_total_title_bouts':'total_title_bouts',\n",
    "                                        'R_age':'age'})\n",
    "\n",
    "#Blue Corner\n",
    "ufc_data_B = ufc_data[['B_fighter','date','B_avg_KD','B_avg_SIG_STR_pct','B_avg_SUB_ATT','B_avg_REV',\n",
    "                         'B_avg_SIG_STR_att','B_avg_SIG_STR_landed','B_avg_TD_att','B_avg_TD_landed','B_avg_HEAD_att',\n",
    "                         'B_avg_HEAD_landed','B_avg_BODY_att','B_avg_BODY_landed','B_avg_LEG_att','B_avg_LEG_landed',\n",
    "                         'B_avg_DISTANCE_att','B_avg_DISTANCE_landed','B_avg_CLINCH_att','B_avg_CLINCH_landed',\n",
    "                         'B_avg_GROUND_att','B_avg_GROUND_landed','B_avg_CTRL_time(seconds)','B_total_title_bouts','B_age']] \\\n",
    "                         .groupby(['B_fighter']).first().reset_index()\n",
    "\n",
    "ufc_data_B['B_fighter'] = ufc_data_B['B_fighter'].str.strip()\n",
    "ufc_data_B = ufc_data_B.rename(columns={'B_fighter':'fighter',\n",
    "                                        'B_avg_KD':'avg_KD',\n",
    "                                        'B_avg_SIG_STR_pct':'avg_SIG_STR_pct',\n",
    "                                        'B_avg_SUB_ATT':'avg_SUB_ATT',\n",
    "                                        'B_avg_REV':'avg_REV',\n",
    "                                        'B_avg_SIG_STR_att':'avg_SIG_STR_att',\n",
    "                                        'B_avg_SIG_STR_landed':'avg_SIG_STR_landed',\n",
    "                                        'B_avg_TD_att':'avg_TD_att',\n",
    "                                        'B_avg_TD_landed':'avg_TD_landed',\n",
    "                                        'B_avg_HEAD_att':'avg_HEAD_att',\n",
    "                                        'B_avg_HEAD_landed':'avg_HEAD_landed',\n",
    "                                        'B_avg_BODY_att':'avg_BODY_att',\n",
    "                                        'B_avg_BODY_landed':'avg_BODY_landed',\n",
    "                                        'B_avg_LEG_att':'avg_LEG_att',\n",
    "                                        'B_avg_LEG_landed':'avg_LEG_landed',\n",
    "                                        'B_avg_DISTANCE_att':'avg_DISTANCE_att',\n",
    "                                        'B_avg_DISTANCE_landed':'avg_DISTANCE_landed',\n",
    "                                        'B_avg_CLINCH_att':'avg_CLINCH_att',\n",
    "                                        'B_avg_CLINCH_landed':'avg_CLINCH_landed',\n",
    "                                        'B_avg_GROUND_att':'avg_GROUND_att',\n",
    "                                        'B_avg_GROUND_landed':'avg_GROUND_landed',\n",
    "                                        'B_avg_CTRL_time(seconds)':'avg_CTRL_time(seconds)',\n",
    "                                        'B_total_title_bouts':'total_title_bouts',\n",
    "                                        'B_age':'age'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_data_final = ufc_data_R.append(ufc_data_B)\n",
    "ufc_data_final['date'] = pd.to_datetime(ufc_data_final['date'])\n",
    "ufc_data_final = ufc_data_final.sort_values(by=['date'], ascending = False).reset_index(drop=True)\n",
    "ufc_data_final = ufc_data_final[['fighter','date','avg_KD','avg_SIG_STR_pct','avg_SUB_ATT','avg_REV',\n",
    "                                 'avg_SIG_STR_att','avg_SIG_STR_landed','avg_TD_att','avg_TD_landed','avg_HEAD_att',\n",
    "                                 'avg_HEAD_landed','avg_BODY_att','avg_BODY_landed','avg_LEG_att','avg_LEG_landed',\n",
    "                                 'avg_DISTANCE_att','avg_DISTANCE_landed','avg_CLINCH_att','avg_CLINCH_landed',\n",
    "                                 'avg_GROUND_att','avg_GROUND_landed','avg_CTRL_time(seconds)','total_title_bouts','age']] \\\n",
    "                                 .groupby(['fighter']).first().reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_data_final['total_title_bouts'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all fighter profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ufc_fighter_details['fighter_name'].nunique())\n",
    "display(ufc_data_final['fighter'].nunique())\n",
    "display(ufc_master_final['fighter'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_fighter_details.rename({'fighter_name': 'fighter'}, axis=1, inplace=True)\n",
    "ufc_fighter_details2 = ufc_fighter_details.merge(ufc_data_final, on = 'fighter', how = 'left')\n",
    "fighter_profiles = ufc_fighter_details2.merge(ufc_master_final, on = 'fighter', how = 'left')\n",
    "fighter_profiles = fighter_profiles[fighter_profiles['wins'].notna() & fighter_profiles['losses'].notna()]\n",
    "display(fighter_profiles.shape)\n",
    "display(fighter_profiles['fighter'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### champions flag\n",
    "the draws end up not mattering. they were already champions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "championlist1 = list(ufc_data_titles['Winner_Name'])\n",
    "#championlist = (draw_champs + championlist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles.loc[fighter_profiles['fighter'].isin(championlist1), 'Champion'] = 1 \n",
    "fighter_profiles['Champion'].fillna(0, inplace = True)\n",
    "ufc_data_titles['Winner_Name'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### two different stance columns: use stance_y which is from ufc_master_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ufc_fighter_details['Stance'].isnull().sum())\n",
    "display(ufc_master_final['Stance'].isnull().sum())\n",
    "display(fighter_profiles['Stance_x'].isnull().sum())\n",
    "display(fighter_profiles['Stance_y'].isnull().sum())\n",
    "#stance_x is from ufc_fighter_details\n",
    "#stance_y is from ufc_final_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles['Stance_x'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles['Stance_y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fighter_profiles[fighter_profiles['Stance_x'] != fighter_profiles['Stance_y']][['fighter', 'Stance_x', 'Stance_y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add weight class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct Weight Class on Final fighter_profile Data Set\n",
    "fighter_profiles['Weightclass'] = ['Heavyweight' if x > 206 \\\n",
    "                                   else 'Light-Heavyweight' if 186<x<=206 \\\n",
    "                                   else 'Middleweight' if 171<x<=186 \\\n",
    "                                   else 'Welterweight' if 156<x<=171 \\\n",
    "                                   else 'Lightweight' if 146<x<=156 \\\n",
    "                                   else 'featherweight' if 136<x<=146 \\\n",
    "                                   else 'Bantamweight' if 126<x<=136 \\\n",
    "                                   else 'flyweight' if 116<x<=125 \\\n",
    "                                   else 'Strawweight' \\\n",
    "                                   for x in fighter_profiles['Weight_lbs']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### divide the columns to types. some drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles.drop(columns=dropped, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feet, and inches convert to inches\n",
    "import regex as re\n",
    "r = re.compile(r\"([0-9]+)' ([0-9]*\\.?[0-9]+)\\\"\")\n",
    "def get_inches(el):\n",
    "    m = r.match(el)\n",
    "    if m == None:\n",
    "        return float('NaN')\n",
    "    else:\n",
    "        return int(m.group(1))*12 + float(m.group(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fighter_profiles[\"Height\"] = fighter_profiles[\"Height\"].astype(str).apply(lambda x:get_inches(x))\n",
    "#fighter_profiles[\"Weight\"] = pd.to_numeric(fighter_profiles[\"Weight\"].str[:3])\n",
    "#fighter_profiles[\"Reach\"] = fighter_profiles[\"Reach\"].str[:2]\n",
    "#fighter_profiles[\"Str_Acc\"] = pd.to_numeric(fighter_profiles[\"Str_Acc\"].str.replace('%', ''))\n",
    "#fighter_profiles[\"Str_Def\"] = pd.to_numeric(fighter_profiles[\"Str_Def\"].str.replace('%', ''))\n",
    "#fighter_profiles[\"TD_Acc\"] = pd.to_numeric(fighter_profiles[\"TD_Acc\"].str.replace('%', ''))\n",
    "#fighter_profiles[\"TD_Def\"] = pd.to_numeric(fighter_profiles[\"TD_Def\"].str.replace('%', ''))\n",
    "fighter_profiles['Str_Acc'] = fighter_profiles['Str_Acc'].str.strip('%').astype(int) / 100\n",
    "fighter_profiles['Str_Def'] = fighter_profiles['Str_Def'].str.strip('%').astype(int) / 100\n",
    "fighter_profiles['TD_Acc'] = fighter_profiles['TD_Acc'].str.strip('%').astype(int) / 100\n",
    "fighter_profiles['TD_Def'] = fighter_profiles['TD_Def'].str.strip('%').astype(int) / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fighter_profiles.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to keep averages from one of the data table, we can check if there are any champions. there are no champs, so lets just delete. about 200 fighters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles[(fighter_profiles['avg_KD'].isnull()) & (fighter_profiles['Champion'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles = fighter_profiles[~fighter_profiles['avg_KD'].isnull()]\n",
    "fighter_profiles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one champion missing stance, he was also a champion. lets manual impute. #'Southpaw', 'Orthodox', 'Switch', 'Open Stance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles.loc[fighter_profiles['fighter'] == 'Juan Espino','Stance_y'] = 'Orthodox' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decision % and KO/TKO %  is nulls, a closer look shows these 271 fighters never won. is it incorrect to replace with 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles[fighter_profiles['Submission%'].isnull()][['fighter', 'win_by_Decision_Majority',\n",
    "       'win_by_Decision_Split', 'win_by_Decision_Unanimous', 'win_by_KO/TKO',\n",
    "       'win_by_Submission', 'win_by_TKO_Doctor_Stoppage', 'wins', 'losses']]['wins'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles.loc[fighter_profiles['Decision%'].isnull(),'Decision%'] = 0 \n",
    "fighter_profiles.loc[fighter_profiles['KO/TKO%'].isnull(),'KO/TKO%'] = 0\n",
    "fighter_profiles.loc[fighter_profiles['Submission%'].isnull(),'Submission%'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine some features for feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles['TD_landed_pct'] = fighter_profiles['avg_TD_landed']/fighter_profiles['avg_TD_att']\n",
    "fighter_profiles['HEAD_pct'] = fighter_profiles['avg_HEAD_landed']/fighter_profiles['avg_HEAD_att']\n",
    "fighter_profiles['BODY_pct'] = fighter_profiles['avg_BODY_landed']/fighter_profiles['avg_BODY_att']\n",
    "fighter_profiles['LEG_pct'] = fighter_profiles['avg_LEG_landed']/fighter_profiles['avg_LEG_att']\n",
    "fighter_profiles['DISTANCE_pct'] = fighter_profiles['avg_DISTANCE_landed']/fighter_profiles['avg_DISTANCE_att']\n",
    "fighter_profiles['CLINCH_pct'] = fighter_profiles['avg_CLINCH_landed']/fighter_profiles['avg_CLINCH_att']\n",
    "fighter_profiles['GROUND_pct'] = fighter_profiles['avg_GROUND_landed']/fighter_profiles['avg_GROUND_att']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in fighter_profiles:\n",
    "    print(fighter_profiles[i].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles.fillna(0, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load and import clusters from k means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = pd.read_csv(\"clusters.csv\")\n",
    "clusters = clusters[['fighter', 'Weightclass', 'Champion', 'Style']]\n",
    "#clusters.loc[:,'style'] = clusters['Weightclass'].astype(str) + clusters['Style'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles = fighter_profiles.merge(clusters[['fighter', 'Style']], on='fighter', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['SLpM', 'Str_Acc', 'SApM', 'Str_Def', 'TD_Avg', 'TD_Acc', 'TD_Def', \n",
    "           'Sub_Avg', 'avg_KD', 'avg_SIG_STR_pct', 'avg_SUB_ATT', 'avg_REV',\n",
    "       'avg_SIG_STR_att', 'avg_SIG_STR_landed', 'avg_CTRL_time(seconds)', \n",
    "           'TD_landed_pct', 'HEAD_pct', 'BODY_pct', 'LEG_pct', 'DISTANCE_pct', 'CLINCH_pct', 'GROUND_pct',   \n",
    "           'total_title_bouts', 'Height_cms', 'Reach_cms',\n",
    "       'Weight_lbs', 'max_lose_streak', 'max_win_streak', 'losses',\n",
    "       'total_rounds_fought', 'win_by_Decision_Majority',\n",
    "       'win_by_Decision_Split', 'win_by_Decision_Unanimous', 'win_by_KO/TKO',\n",
    "       'win_by_Submission', 'win_by_TKO_Doctor_Stoppage', 'wins',\n",
    "       'min_lose_streak', 'min_win_streak', 'avg_odds', 'avg_lose_streak',\n",
    "       'avg_win_streak', 'Decision%', 'KO/TKO%', 'Submission%']\n",
    "category = ['Stance_y', 'fighter', 'Champion', 'Weightclass', 'Style']\n",
    "\n",
    "dropped = ['Stance_x', 'date', 'DOB', 'Height', 'Weight', 'Reach', 'age']\n",
    "\n",
    "#some to drop after combining\n",
    "poss_drops = ['avg_TD_att', 'avg_TD_landed', 'avg_HEAD_att', 'avg_HEAD_landed', 'avg_BODY_att', 'avg_BODY_landed',\n",
    "       'avg_LEG_att', 'avg_LEG_landed', 'avg_DISTANCE_att',\n",
    "       'avg_DISTANCE_landed', 'avg_CLINCH_att', 'avg_CLINCH_landed',\n",
    "       'avg_GROUND_att', 'avg_GROUND_landed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Feature Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['Champion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles[numeric].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multicollinearity and Removing Redundancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create correlation matrix\n",
    "corr_matrix = fighter_profiles[numeric + target].corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find features with correlation greater than 0.95\n",
    "high_corr = [column for column in upper.columns if any(upper[column] > 0.70)]\n",
    "\n",
    "# Drop features \n",
    "#df.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (30,25))\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "ax = sns.heatmap(fighter_profiles[high_corr + target].corr(), annot = True, center = True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a lot of these are intuitive:\n",
    "1. reach and weight\n",
    "2. wins and losses\n",
    "3. takedowns and control time\n",
    "4. body land vs body attack\n",
    "etc. we can leave these here for now and remove via regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lets have a 3 fight minimum in the UFC before they are legible for Champion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles['total_fights'] = fighter_profiles['losses'] + fighter_profiles['wins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fighter_profiles = fighter_profiles[fighter_profiles['total_fights'] >=3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fighter_profiles\n",
    "plt.figure(figsize = (12,10))\n",
    "sns.set(font_scale=1.2)\n",
    "data = fighter_profiles.groupby(\"Weightclass\")['fighter'].count()\n",
    "data.plot.pie(autopct=\"%.1f%%\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fighter_profiles\n",
    "plt.figure(figsize = (12,10))\n",
    "sns.set(font_scale=1.2)\n",
    "data = fighter_profiles.groupby(\"Stance_y\")['fighter'].count()\n",
    "data.plot.pie(autopct=\"%.1f%%\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=fighter_profiles, x=\"Weight_lbs\")\n",
    "plt.title('Weight Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=fighter_profiles, x=\"Height_cms\")\n",
    "plt.title('Height Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=fighter_profiles, x=\"Reach_cms\")\n",
    "plt.title('Reach Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles[['fighter', 'Decision%', 'KO/TKO%', 'Submission%', 'total_fights', 'Champion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,10))\n",
    "sns.histplot(data=fighter_profiles, x=\"total_fights\", hue = 'Champion', bins = 50)\n",
    "plt.title('Fight count Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_data_titles['Winner_Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,10))\n",
    "\n",
    "champsfiltered = ufc_data_titles[ufc_data_titles.groupby(\"Winner_Name\")['Winner_Name'].transform('size') > 2]\n",
    "p = champsfiltered.Winner_Name.value_counts().sort_values().plot(kind = 'barh')\n",
    "sns.set(font_scale = 1.5)\n",
    "p.set_xlabel(\"Number of Title Fights Won (at least 2)\", fontsize = 20)\n",
    "p.set_ylabel(\"Champions\", fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles['Weightclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles[fighter_profiles['Champion'] == 1]['Weightclass'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dummy the stance variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles = fighter_profiles.rename(columns={'Stance_y':'Stance'})\n",
    "fighter_profiles = pd.get_dummies(fighter_profiles, columns=['Stance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into its weight classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lightweight = fighter_profiles[fighter_profiles['Weightclass'] == 'Lightweight']\n",
    "Welterweight= fighter_profiles[fighter_profiles['Weightclass'] == 'Welterweight']\n",
    "Bantamweight= fighter_profiles[fighter_profiles['Weightclass'] == 'Bantamweight']\n",
    "featherweight= fighter_profiles[fighter_profiles['Weightclass'] == 'featherweight']\n",
    "Middleweight= fighter_profiles[fighter_profiles['Weightclass'] == 'Middleweight']\n",
    "LightHeavyweight= fighter_profiles[fighter_profiles['Weightclass'] == 'Light-Heavyweight']\n",
    "flyweight= fighter_profiles[fighter_profiles['Weightclass'] == 'flyweight']\n",
    "Heavyweight= fighter_profiles[fighter_profiles['Weightclass'] == 'Heavyweight']\n",
    "Strawweight= fighter_profiles[fighter_profiles['Weightclass'] == 'Strawweight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dummy the styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lightweight = pd.get_dummies(Lightweight, columns=['Style'])\n",
    "Welterweight = pd.get_dummies(Welterweight, columns=['Style'])\n",
    "Bantamweight = pd.get_dummies(Bantamweight, columns=['Style'])\n",
    "featherweight = pd.get_dummies(featherweight, columns=['Style'])\n",
    "Middleweight = pd.get_dummies(Middleweight, columns=['Style'])\n",
    "LightHeavyweight = pd.get_dummies(LightHeavyweight, columns=['Style'])\n",
    "flyweight = pd.get_dummies(flyweight, columns=['Style'])\n",
    "Heavyweight = pd.get_dummies(Heavyweight, columns=['Style'])\n",
    "Strawweight = pd.get_dummies(Strawweight, columns=['Style'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dummy the  weightclass variable for total fighterProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles = pd.get_dummies(fighter_profiles, columns=['Weightclass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## features and target: split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles['Champion'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_profiles['Champion'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "def split_data(df, scaling, oversample1):\n",
    "    xcols = list(df.columns)\n",
    "    xcols.remove('fighter')\n",
    "    xcols.remove('Champion')\n",
    "    xcols.remove('Weightclass')\n",
    "    ycols = ['Champion']\n",
    "    \n",
    "    X = df[xcols]\n",
    "    y = df[ycols]\n",
    "    \n",
    "    X_ = X.copy()\n",
    "    \n",
    "    #scaling = 'minmax'\n",
    "    #scaling = 'standard'\n",
    "    #scaling = 'None'\n",
    "\n",
    "    if scaling == 'minmax':\n",
    "        #minmax\n",
    "        feature_scaler = MinMaxScaler()\n",
    "        X_[list(X_.columns)] = feature_scaler.fit_transform(X_)\n",
    "    elif scaling == 'standard':\n",
    "        #standardization\n",
    "        feature_scaler = StandardScaler()\n",
    "        X_[list(X_.columns)] = feature_scaler.fit_transform(X_)\n",
    "    else:\n",
    "        X_[list(X_.columns)] = X_\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y, shuffle = True, test_size=0.30, random_state=1)\n",
    "    \n",
    "    if oversample1 == True:\n",
    "        oversample = SMOTE()\n",
    "        X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        print('no oversample')\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = split_data(Lightweight, 'standard', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform GridSearchCV to tune best-fit LR model\n",
    "def model_train_search(X_train, y_train, penalty, solver = 'liblearner'):\n",
    "    param = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "            'l1_ratio': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 0.8, 0.9, 0.99, 1]}\n",
    "\n",
    "    lr_model = LogisticRegression(penalty=penalty, solver=solver, class_weight='balanced', l1_ratio=0.5)\n",
    "    gs_model = GridSearchCV(cv=5, estimator=lr_model, param_grid=param, scoring='f1') #f1 #‘average_precision’ #balanced_accuracy\n",
    "    gs_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # Train a LR model with best parameters\n",
    "    model = LogisticRegression(**gs_model.best_params_, penalty=penalty, solver=solver, class_weight='balanced', max_iter=10000)\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    display(model.n_iter_)\n",
    "    display(model.get_params)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_outputs(X_test, y_test, model):\n",
    "    predictions = model.predict(X_test)\n",
    "    predict_probs = model.predict_proba(X_test)\n",
    "    scores = model.score(X_test, y_test)\n",
    "\n",
    "    # Predicted values\n",
    "    y_pred = predictions\n",
    "    # Actual values\n",
    "    y_act = y_test\n",
    "\n",
    "    # Printing the confusion matrix\n",
    "    print(metrics.confusion_matrix(y_act, y_pred, labels=[0, 1]))\n",
    "    print(metrics.confusion_matrix(y_act, y_pred, normalize = 'true'))\n",
    "    # Printing the precision and recall, among other metrics\n",
    "    print(metrics.classification_report(y_act, y_pred))\n",
    "    cm = confusion_matrix(y_act, y_pred)\n",
    "    \n",
    "    \n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, fmt='g', ax=ax,cmap=\"YlGnBu\");  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "    ax.set_title('Confusion Matrix'); \n",
    "    #ax.xaxis.set_ticklabels(['business', 'health']); ax.yaxis.set_ticklabels(['health', 'business']);\n",
    "    \n",
    "    return predictions, predict_probs, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_loop(df, scaling, oversample):\n",
    "    X_train, X_test, y_train, y_test = split_data(df, scaling, oversample)\n",
    "    #model1 = model_train_search(X_train, y_train, 'l1', 'liblinear')\n",
    "    #best1 = predict_outputs(X_test, y_test, model1)\n",
    "    #model2 = model_train_search(X_train, y_train, 'l2', 'liblinear')\n",
    "    #best2 = predict_outputs(X_test, y_test, model2)\n",
    "    model3 = model_train_search(X_train, y_train, 'elasticnet', 'saga')\n",
    "    best3 = predict_outputs(X_test, y_test, model3)\n",
    "    #return best1, best2, best3\n",
    "    return model3, best3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ForestClassify(X_train, y_train):\n",
    "    rfc=RandomForestClassifier(random_state=42)\n",
    "    param_grid = { \n",
    "    'n_estimators': [200, 500, 1000],\n",
    "    'max_features': ['auto'],#, 'sqrt', 'log2'],\n",
    "    'max_depth' : [3,4,5,7,8,],\n",
    "    'criterion' :['gini']#, 'entropy']\n",
    "}\n",
    "    CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "    CV_rfc.fit(X_train, y_train)\n",
    "    \n",
    "    print(CV_rfc.best_params_)\n",
    "    \n",
    "    rfc1=RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 200, max_depth=7, criterion='gini')\n",
    "    rfc1.fit(X_train, y_train)\n",
    "    ans = predict_outputs(X_test, y_test, rfc1)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "def importance(model, n):\n",
    "    importance = model[0].coef_[0]\n",
    "    sorted = np.sort(importance)[-n:]\n",
    "    indices = np.argsort(importance)[-n:]\n",
    "    feats = [c[0].feature_names_in_[i] for i in indices][-n:]\n",
    "    print(sorted)\n",
    "    print(indices)\n",
    "    print(feats)\n",
    "    plt.bar(feats, sorted, align='center')\n",
    "    plt.xticks(rotation = 90) \n",
    "    plt.title(\"Top Positive Coefficient Value\")\n",
    "    #plt.xlabel(\"Average Pulse\")\n",
    "    plt.ylabel(\"Coefficient Value\")\n",
    "    plt.show()\n",
    "    return [sorted, indices, feats]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(Bantamweight, 'standard', True)\n",
    "Forest = ForestClassify(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(Welterweight, 'standard', True)\n",
    "Forest = ForestClassify(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(Middleweight, 'standard', True)\n",
    "Forest = ForestClassify(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(Lightweight, 'standard', True)\n",
    "Forest = ForestClassify(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(featherweight, 'standard', True)\n",
    "Forest = ForestClassify(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(Heavyweight, 'standard', True)\n",
    "Forest = ForestClassify(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(LightHeavyweight, 'standard', True)\n",
    "Forest = ForestClassify(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = full_loop(Bantamweight, 'standard', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = importance(a,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "b = full_loop(Welterweight, 'standard', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = importance(b,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = full_loop(Middleweight, 'standard', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = importance(c,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = full_loop(Lightweight, 'standard', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = importance(d,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = full_loop(featherweight, 'standard', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = importance(e,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = full_loop(Heavyweight, 'standard', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = importance(f,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = full_loop(LightHeavyweight, 'standard', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = importance(g,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backup Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model_train_search(X_train, y_train, 'none', 'lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best = predict_outputs(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_train_search(X_train, y_train, 'l1', 'liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = model.coef_[0]\n",
    "removed_features = pd.Series(X_train.columns)[list(coef==0)]\n",
    "imp_features = pd.Series(X_train.columns)[list(coef!=0)]\n",
    "#X_train = X_train[imp_features]\n",
    "#X_test = X_test[imp_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = predict_outputs(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train with only important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train[imp_features]\n",
    "X_test2 = X_test[imp_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = model_train_search(X_train2, y_train, 'l1', 'liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = predict_outputs(X_test2, y_test, model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_train_search(X_train, y_train, 'l2', 'liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = predict_outputs(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_train_search(X_train, y_train, 'elasticnet', 'saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = predict_outputs(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc=RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 500, 1000],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [5,7,8,9,10],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "\n",
    "CV_rfc.best_params_\n",
    "\n",
    "rfc1=RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 200, max_depth=7, criterion='gini')\n",
    "rfc1.fit(X_train, y_train)\n",
    "\n",
    "pred=rfc1.predict(X_test)\n",
    "predict_outputs(X_test, y_test, rfc1)\n",
    "\n",
    "print(\"Accuracy for Random Forest on CV data: \",accuracy_score(y_test,pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
